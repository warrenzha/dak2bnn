{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-08T02:11:25.411432Z",
     "start_time": "2024-10-08T02:11:23.978612Z"
    }
   },
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import gpytorch"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:11:25.537943Z",
     "start_time": "2024-10-08T02:11:25.411432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def squared_exponential_kernel(x1, x2, length_scale=1.0, sigma_f=1.0):\n",
    "    \"\"\"Compute the Squared Exponential (RBF) kernel between two sets of inputs.\"\"\"\n",
    "    sqdist = cdist(x1, x2, 'sqeuclidean')\n",
    "    return sigma_f**2 * np.exp(-0.5 / length_scale**2 * sqdist)\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Training data is 200 points in [-7,7] inclusive regularly spaced\n",
    "num_samples = 20  # Number of samples to generate\n",
    "length_scale = 1.0  # Length scale of the SE kernel\n",
    "sigma_f = 1.0  # Signal variance\n",
    "\n",
    "# Generate input points and compute the covariance matrix using SE kernel\n",
    "train_x = np.linspace(-7, 7, num_samples).reshape(-1, 1)\n",
    "train_x_cov = squared_exponential_kernel(train_x, train_x, length_scale, sigma_f)\n",
    "# Generate zero-mean Gaussian data with the computed covariance matrix\n",
    "train_y = np.random.multivariate_normal(np.zeros(num_samples), train_x_cov) + 0.4 * np.random.randn(num_samples)\n",
    "\n",
    "x_tensor = torch.tensor(train_x, dtype=torch.float32).view(-1, 1)\n",
    "y_tensor = torch.tensor(train_y, dtype=torch.float32)"
   ],
   "id": "383deb2157073c89",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:11:25.541615Z",
     "start_time": "2024-10-08T02:11:25.537943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DNN, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.hidden(x)"
   ],
   "id": "399a925e5257bcdc",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:11:25.555498Z",
     "start_time": "2024-10-08T02:11:25.542232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "        def __init__(self, x_tensor, y_tensor, likelihood):\n",
    "            super(GPRegressionModel, self).__init__(x_tensor, y_tensor, likelihood)\n",
    "            self.mean_module = gpytorch.means.ConstantMean()\n",
    "            self.covar_module = gpytorch.kernels.GridInterpolationKernel(\n",
    "                gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=2)),\n",
    "                num_dims=2, \n",
    "                grid_size=32,\n",
    "            )\n",
    "            self.feature_extractor = DNN(input_dim=1, output_dim=2)\n",
    "\n",
    "            # This module will scale the NN features so that they're nice values\n",
    "            self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # We're first putting our data through a deep net (feature extractor)\n",
    "            projected_x = self.feature_extractor(x)\n",
    "            projected_x = self.scale_to_bounds(projected_x)  # Make the NN values \"nice\"\n",
    "\n",
    "            mean_x = self.mean_module(projected_x)\n",
    "            covar_x = self.covar_module(projected_x)\n",
    "            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "        \n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "dkl_model = GPRegressionModel(x_tensor, y_tensor, likelihood)"
   ],
   "id": "41846ffffe05d6d4",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:12:57.121955Z",
     "start_time": "2024-10-08T02:12:57.111227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dak.utils.sparse_design.design_class import HyperbolicCrossDesign\n",
    "from dak.kernels.laplace_kernel import LaplaceProductKernel\n",
    "from dak.layers.functional import ScaleToBounds\n",
    "from dak.layers.activation import Amk1d\n",
    "from dak.layers.linear import LinearFlipout\n",
    "\n",
    "class DAKMC(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, design_class, kernel):\n",
    "        super(DAKMC, self).__init__()\n",
    "\n",
    "        self.feature_extractor = DNN(input_dim=input_dim, output_dim=2)\n",
    "        self.norm = nn.BatchNorm1d(2)\n",
    "        # self.norm = ScaleToBounds(-1., 1.)\n",
    "        self.mk1 = Amk1d(in_features=2, n_level=5, input_lb=-3., input_ub=3., design_class=design_class, kernel=kernel)\n",
    "        self.gp1 = LinearFlipout(self.mk1.out_features, output_dim)\n",
    "\n",
    "    def forward(self, x, return_kl=True):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.mk1(x).flatten(1)\n",
    "        x, kl = self.gp1(x)\n",
    "        if return_kl:\n",
    "            return x, kl\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "dak_mc = DAKMC(input_dim=1, \n",
    "               output_dim=1, \n",
    "               design_class=HyperbolicCrossDesign, \n",
    "               kernel=LaplaceProductKernel(0.3),\n",
    "               )"
   ],
   "id": "f42dfba2ebfbda8b",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:11:37.853338Z",
     "start_time": "2024-10-08T02:11:25.579547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_gpr(model, criterion, optimizer, epochs=200):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # Zero backprop gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Get output from model\n",
    "        output = model(x_tensor)\n",
    "        # Calc loss and backprop derivatives\n",
    "        loss = - criterion(output, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item()}')\n",
    "            \n",
    "    return losses\n",
    "\n",
    "# Use the adam optimizer\n",
    "dkl_optimizer = torch.optim.Adam([\n",
    "    {'params': dkl_model.feature_extractor.parameters()},\n",
    "    {'params': dkl_model.covar_module.parameters()},\n",
    "    {'params': dkl_model.mean_module.parameters()},\n",
    "    {'params': dkl_model.likelihood.parameters()},\n",
    "], lr=0.01)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "dkl_criterion = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, dkl_model)\n",
    "\n",
    "dkl_losses = train_gpr(dkl_model, dkl_criterion, dkl_optimizer, epochs=1000)"
   ],
   "id": "38360e5f77fca70c",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:49:12.733660Z",
     "start_time": "2024-10-08T02:49:07.910551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "def train_dak(model, criterion, optimizer, epochs=200, mc_sampling=True):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        if mc_sampling:\n",
    "            output_ = []\n",
    "            kl_ = []\n",
    "            for mc_run in range(2):\n",
    "                output, kl = dak_mc(x_tensor)\n",
    "                output_.append(output)\n",
    "                kl_.append(kl)\n",
    "            output = torch.mean(torch.stack(output_), dim=0)\n",
    "            kl = torch.mean(torch.stack(kl_), dim=0)\n",
    "            loss = criterion(output, y_tensor.view(-1,1)) + kl / len(train_x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item()}')\n",
    "            \n",
    "    return losses\n",
    "\n",
    "dak_mc_optimizer = torch.optim.Adam(dak_mc.parameters(), lr=0.01)\n",
    "dak_mc_criterion = nn.MSELoss()\n",
    "\n",
    "dak_mc_losses = train_dak(dak_mc, dak_mc_criterion, dak_mc_optimizer, epochs=1000)"
   ],
   "id": "a71b2c8db9479ecd",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:11:42.823997Z",
     "start_time": "2024-10-08T02:11:42.285780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "num_samples = 200  # Number of samples to generate\n",
    "# Generate input points and compute the covariance matrix using SE kernel\n",
    "test_x = np.linspace(-12, 12, num_samples).reshape(-1, 1)\n",
    "test_x_cov = squared_exponential_kernel(test_x, test_x, length_scale, sigma_f)\n",
    "# Generate zero-mean Gaussian data with the computed covariance matrix\n",
    "test_y = np.random.multivariate_normal(np.zeros(num_samples), test_x_cov) + 0.1 * np.random.randn(num_samples)\n",
    "\n",
    "test_x_tensor = torch.tensor(test_x, dtype=torch.float32).view(-1, 1)\n",
    "test_y_tensor = torch.tensor(test_y, dtype=torch.float32)"
   ],
   "id": "87d1cdb3c2f970a0",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:11:42.853118Z",
     "start_time": "2024-10-08T02:11:42.823997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_gpr(model, x):\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    \n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = likelihood(model(x))\n",
    "    \n",
    "    mean = observed_pred.mean.numpy()\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    \n",
    "    return mean, lower.numpy(), upper.numpy()\n",
    "\n",
    "dkl_pred_mean, dkl_pred_lower, dkl_pred_upper = evaluate_gpr(dkl_model, test_x_tensor)"
   ],
   "id": "e8737aa926319c81",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:49:20.224017Z",
     "start_time": "2024-10-08T02:49:20.187368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_dak(model, x, mc_sampling=True):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if mc_sampling:\n",
    "            predicts = []\n",
    "            for mc_run in range(20):\n",
    "                output = model(x, return_kl=False)\n",
    "                predicts.append(output.cpu().data.numpy())\n",
    "                \n",
    "            pred_mean = np.mean(predicts, axis=0)\n",
    "            pred_std = np.std(predicts, axis=0)\n",
    "            lower = pred_mean - 2 * pred_std\n",
    "            upper = pred_mean + 2 * pred_std\n",
    "    \n",
    "    return pred_mean, lower.squeeze(), upper.squeeze()\n",
    "\n",
    "dak_mc_pred_mean, dak_mc_pred_lower, dak_mc_pred_upper = evaluate_dak(dak_mc, test_x_tensor)"
   ],
   "id": "8dc8067ded1b7985",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:20:04.769562Z",
     "start_time": "2024-10-08T02:20:04.765015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot(mean, lower, upper, legend=True, save_path=None):\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    \n",
    "    # Plot training data as black stars\n",
    "    ax.plot(x_tensor.numpy(), y_tensor.numpy(), 'k*')\n",
    "    \n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x_tensor.numpy(), mean, 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x_tensor.numpy().squeeze(), lower, upper, alpha=0.5)\n",
    "    ax.set_xlim([-12,12])\n",
    "    ax.set_ylim([-4, 4])\n",
    "    if legend:\n",
    "        ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "        \n",
    "    plt.savefig(save_path)"
   ],
   "id": "cc2b35d176808a2f",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:20:06.070040Z",
     "start_time": "2024-10-08T02:20:05.995215Z"
    }
   },
   "cell_type": "code",
   "source": "plot(dkl_pred_mean, dkl_pred_lower, dkl_pred_upper, legend=False, save_path='toy_dkl.pdf')",
   "id": "c79613f9cabd2c38",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:49:24.152114Z",
     "start_time": "2024-10-08T02:49:24.074432Z"
    }
   },
   "cell_type": "code",
   "source": "plot(dak_mc_pred_mean, dak_mc_pred_lower, dak_mc_pred_upper, legend=False, save_path='toy_dak.pdf')",
   "id": "b157e441e57353a6",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T02:11:43.134808Z",
     "start_time": "2024-10-08T02:11:43.132120Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aafc8776d162574d",
   "execution_count": 13,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
